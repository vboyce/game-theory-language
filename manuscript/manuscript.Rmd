---
title: "Game theory and language: a cautionary tale"
authors:
  - name: Veronica Boyce
    department: Department of Psychology
    affiliation: Stanford University
    email: vboyce@stanford.edu
  - name: Avidit Acharya
    department: Department of Political Science
    affiliation: Stanford University
  - name: Michael C. Frank
    department: Department of Psychology
    affiliation: Stanford University
abstract: |
  An attempt was made TODO
bibliography: references.bib
biblio-style: unsrt
output: 
  rticles::arxiv_article:
    extra_dependencies: ["float", "subcaption", "multirow", "array"]
header-includes:
 - \usepackage{float}
 - \usepackage{subcaption}
 - \usepackage{multirow}
 - \usepackage{array}
 - \usepackage{setspace}\singlespacing
 - \renewcommand{\textfraction}{0.00}
 - \renewcommand{\topfraction}{1}
 - \renewcommand{\bottomfraction}{1}
 - \renewcommand{\floatpagefraction}{1}
 - \setcounter{topnumber}{5}
 - \setcounter{bottomnumber}{5}
 - \setcounter{totalnumber}{6}  
 - \usepackage{caption, subcaption}
 - \usepackage{placeins}

---

# Introduction

How do we use language to coordinate with each other?

The use of language and the formation of linguistic conventions in pure reference games is studied frequently, but the role of language is studied less in other situations with more complicated goals that may not be fully aligned between participants. 

In prior work, we tried to look at the role of language in a 3-player negotiation game where incentives were either fully-aligned or competitive between players. We found some evidence that language use improved performance, and that the referential language used to pick out targets showed some signs of conventionalization over time. However, this was a game we had created, so there were not theoretical or analytic predictions about what the optimal strategies were either with or without language, and therefore, when or how communication (via language) might improve performance. 

Here, we attempted to bridge that gap, by looking at the role of language in two classic game theory games. By using set-ups that are well studied in the game theory literature, we had a rich body of work understanding how rational agents would play, and when linguistic coordination could be useful. 

We focus on two games from within the 2x2 game space: Prisoner's Dilemma (PD) and Bach or Stravinsky (BoS). 

TODO payout table

From game theory analysis, communication should not help in PD as it would be "cheap talk" -- that is, regardless of what the opponent player says, the equilibrium does not change, because there is not an incentive to be truthful. Thus, the prediction from game theory is that among rational agents playing a one-shot game of PD, they will end up in the Nash equilibrium. 

For BoS, there are two pure Nash equilibrium, and thus there is a coordination challenge to agree on which one to go to. In this case, a message from one player saying what they will select will be credible -- having said that, they are incentivized to act on it, and their partner can do better by listening to it. There may be competition over which of the two equilibrium options to agree on, but both players want to go for the same cell. Thus, the prediction is that language will be beneficial in BoS. 

To foreshadow the results, we found that *using* language showed some effect of helping improve results when people used it (including the possibility of cross-round transfer). However, the rate of uptake of the chat interface was low (despite our best efforts), and so we did not find robust effects of condition (chat or no chat). We also cannot know that differences between *those who could use and did use the chat* and other groups were due to the chat use as opposed to selection confounds on who chooses to use the chat. A qualitative look at the language and post-experiment reports reveals various ways overall strategies for achieving fairness (in both conditions) and various strategies for identifying the target each round (when language was used). 

Thus, we still suspect that there probably is something interesting about when language is strategically useful and what sort of procedural and referential language is used. That said, we are unable to provide evidence because over 5 experiments (+ pilots) we continually ran into issues getting sufficient uptake of the condition manipulation, from which we eventually concluded that it was not worth our running additional experiments. 

All data and code is available. 

# Methods
```{r set-up, include=F}
knitr::opts_chunk$set(
  out.width = "\\textwidth",
  fig.align = "center", fig.width = 8, fig.height = 4, fig.crop = F, fig.align = "center", fig.env = "figure",
  fig.pos = "tb", fig.path = "figs/",
  echo = F, warning = F, cache = F,
  message = F, sanitize = T
)
library(tidyverse)
library(jsonlite)
library(here)
library(rlang)
library(lme4)
library(brms)
library(rstan)
library(viridis)
library(knitr)

theme_set(theme_bw())

source(here("manuscript/prep.R"))

stats <- function(model, row, decimal = 2) {
  model <- model |>
    mutate(
      Estimate = round(Estimate, digits = decimal),
      Lower = round(lower, digits = decimal),
      Upper = round(upper, digits = decimal),
      `Credible Interval` = str_c("[", Lower, ", ", Upper, "]")
    ) |>
    select(Term, Estimate, `Credible Interval`)
  str_c(model[row, 1], ": ", model[row, 2], " ", model[row, 3])
}

stats_text <- function(model, row, decimal = 2) {
  model <- model |>
    mutate(
      Estimate = round(Estimate, digits = decimal),
      Lower = round(lower, digits = decimal),
      Upper = round(upper, digits = decimal),
      `Credible Interval` = str_c("[", Lower, ", ", Upper, "]")
    ) |>
    select(Term, Estimate, `Credible Interval`)
  str_c(model[row, 2], "  ", model[row, 3])
}

```


```{=latex}
	\begin{figure}
		\caption{Reward structure for each game. In each cell, the reward for X is shown before the reward for Y. }
		\label{payoff-matrix}
		\setlength{\extrarowheight}{2pt}
		\begin{subfigure}[b]{0.45\textwidth}
			\caption{PD generalized -- Each player prefers B to A, but players prefer AA to BB. }
			\label{payoff-PD}
		\begin{tabular}{cc|c|c|}
			& \multicolumn{1}{c}{} & \multicolumn{2}{c}{Player $Y$}\\
			& \multicolumn{1}{c}{} & \multicolumn{1}{c}{$A$}  & \multicolumn{1}{c}{$B$} \\\cline{3-4}
			\multirow{2}*{Player $X$}  & $A$ & $(2,2)$ & $(0,3)$ \\\cline{3-4}
			& $B$ & $(3,0)$ & $(1,1)$ \\\cline{3-4}
		\end{tabular}
		\end{subfigure}
		~~~~
			\begin{subfigure}[b]{0.45\textwidth}
			\caption{BoS generalized-- X prefers AA and Y prefers BB, but both prefer either to AB or BA.}
			\label{payoff-BoS}
			\begin{tabular}{cc|c|c|}
				& \multicolumn{1}{c}{} & \multicolumn{2}{c}{Player $Y$}\\
				& \multicolumn{1}{c}{} & \multicolumn{1}{c}{$A$}  & \multicolumn{1}{c}{$B$} \\\cline{3-4}
				\multirow{2}*{Player $X$}  & $A$ & $(2,1)$ & $(0,0)$ \\\cline{3-4}
				& $B$ & $(0,0)$ & $(1,2)$ \\\cline{3-4}
			\end{tabular}
		\end{subfigure}
		\bigskip
		
		\bigskip
								\begin{subfigure}[b]{0.45\textwidth}
			\caption{Example PD easy: Here the total reward from AA is greater that the total reward from AB or BA.}
			\label{payoff-PDeasy}
			\begin{tabular}{cc|c|c|}
				& \multicolumn{1}{c}{} & \multicolumn{2}{c}{Player $Y$}\\
				& \multicolumn{1}{c}{} & \multicolumn{1}{c}{$A$}  & \multicolumn{1}{c}{$B$} \\\cline{3-4}
				\multirow{2}*{Player $X$}  & $A$ & $(5,5)$ & $(0,7)$ \\\cline{3-4}
				& $B$ & $(7,0)$ & $(2,2)$ \\\cline{3-4}
			\end{tabular}
		\end{subfigure}
		~~~~
		\begin{subfigure}[b]{0.45\textwidth}
			\caption{Example BoS normal: The scale of the two rewards is relatively similar. }
			\label{payoff-BoSnormal}
			\begin{tabular}{cc|c|c|}
				& \multicolumn{1}{c}{} & \multicolumn{2}{c}{Player $Y$}\\
				& \multicolumn{1}{c}{} & \multicolumn{1}{c}{$A$}  & \multicolumn{1}{c}{$B$} \\\cline{3-4}
				\multirow{2}*{Player $X$}  & $A$ & $(6, 2)$ & $(0,0)$ \\\cline{3-4}
				& $B$ & $(0,0)$ & $(2,6)$ \\\cline{3-4}
			\end{tabular}
		\end{subfigure}
		
		\bigskip
		\bigskip
			\begin{subfigure}[b]{0.45\textwidth}
			\caption{Example PD hard: Here the total reward from AB or BA is greater than AA because the highest reward is more than double the second highest.}
			\label{payoff-PDhard}
			\begin{tabular}{cc|c|c|}
				& \multicolumn{1}{c}{} & \multicolumn{2}{c}{Player $Y$}\\
				& \multicolumn{1}{c}{} & \multicolumn{1}{c}{$A$}  & \multicolumn{1}{c}{$B$} \\\cline{3-4}
				\multirow{2}*{Player $X$}  & $A$ & $(4,4)$ & $(0,11)$ \\\cline{3-4}
				& $B$ & $(11,0)$ & $(2,2)$ \\\cline{3-4}
			\end{tabular}
		\end{subfigure}
		~~~~
				\begin{subfigure}[b]{0.45\textwidth}
			\caption{Example BoS spike: One of the rewards is much higher than the other, raising the stakes of which of AA or BB to aim for. }
			\label{payoff-BoSspike}
			\begin{tabular}{cc|c|c|}
				& \multicolumn{1}{c}{} & \multicolumn{2}{c}{Player $Y$}\\
				& \multicolumn{1}{c}{} & \multicolumn{1}{c}{$A$}  & \multicolumn{1}{c}{$B$} \\\cline{3-4}
				\multirow{2}*{Player $X$}  & $A$ & $(28,5)$ & $(0,0)$ \\\cline{3-4}
				& $B$ & $(0,0)$ & $(5,28)$ \\\cline{3-4}
			\end{tabular}
		\end{subfigure}
		
		\end{figure}
		
```


## Overall methods

All experiments were implemented in Empirica (v1). We recruited participants via Prolific and directed them to our website where they were paired up to play a game with another participant in real time. 

The experiment consisted first of consent and instructions. Then participants (in all conditions) were given 3 minutes to freely chat with their partner using the chat box. Instructions for experiments 1-3 were: "You may have seen similar games where your partner is really a bot. This isn't one of those! You have been paired with another human participant who was also recruited from Prolific at the same time." In experiments 4 and 5, conducted after the widespread awareness of LLM chatbots like Chat-GPT, we became more explicit: "We are aware that there are similar games where your partner is a bot (or ChatGPT). *THIS IS NOT ONE OF THOSE.* We are cognitive scientists at a university, and our ethics approval (IRB) doesn't allow us to deceive participants. You have been paired with another participant who was also recruited from Prolific via the same task you were." This was intended to convince participants their partner really was human and not a bot (after high "is a bot" ratings in pre-experiment-1 pilot studies). A few potential prompts for conversation were given.

Then participants moved onto the main experiment, where on each trial, they saw a payout grid for differently colored treasure chests and were asked to click which chest they wanted to open. Each pair completed 40 trials, with the payoffs dependent on the experiment condition (see below). In experiments 1,2,3 and 5, participants saw a running bonus score for themselves and their partner, as their bonus payment was proportional to the sum of the rewards they owned. On experiment 4, participants were instead paid proportional to the results of 4 randomly selected trials, and were not shown a cumulative payoff score. 

After the experiment, participants completed a survey about their experience, including their strategy and whether they thought they were playing with a real person, before seeing a debrief and being redirected back to prolific to receive payment. 

```{r}
all_rounds |>
  select(gameId, expt, chat_cond) |>
  unique() |>
  group_by(expt, chat_cond) |>
  tally() |>
  mutate(n = 2 * n) |>
  pivot_wider(names_from = chat_cond, values_from = n) |>
  kable(caption = "Number of participants in each experiment and each condition. \\label{participants}")
```

## Conditions
For all experiments, we set parameters for the ratios between trial types and the ranges of payout values for each trial type. We used a sampling and randomization approach (see code for details), so different games saw different orders of trials and different values of trials, from the same distributions. 

All experiments did both chat and no-chat versions as a between groups manipulation. The number of participants in each experiment and condition is in Table \ref{participants}. 
TODO diagram 

Trial types:

* normal PD trials were created by sampling 3 values from 1-9 (without replacement) for the payoffs, with 0 always as the sucker payoff, with the preference order corresponding to PD structure.

* easy PD trials were created by sampling 3 values from 1-12 (without replacement) for the payoffs, with 0 always as the sucker payoff, conditioned on the second highest payoff (AA) being at least half of the highest AB/BA payoff. This ensures that the total payoff for AA is greater than or equal to the defect payoff. 

* hard PD trials  were created by sampling 3 values from 1-12 (without replacement) for the payoffs, with 0 always as the sucker payoff, conditioned on the highest payoff (AB/BA) being greater than double the cooperate AA payoff. This ensures that the defect payoff for AB/BA is greater than the total payoff for both cooperating. 

* normal BoS trials were created by sampling from 2-9 (without replacement) for the AA and BB payoffs. THe off diagonal payoffs were always 0. 

* spike BoS trials were created from sampling one reward from 3-7 and one reward from 25-30. Off diagonal payoffs were always 0. 

Experiments:

*Expt 1* (https://osf.io/8fnze): Between - group manipulation of either all normal PD trials or all normal BoS trials. 

*Expt 2* (https://osf.io/5au2r): A within-group version of experiment 1. Each game had roughly half and half normal PD and normal BoS trials.

During data analysis for experiment 2, we realized that we had been misdisplaying the off diagonal rewards for PD for one player in each game. This was fixed for subsequent experiments.

*Expt 3* (https://osf.io/c274z): Each game had a mix of easy PD, hard PD, normal BoS, and spike BoS.  Of the 40 trials, exactly 4, at pre-set locations in the trial order were spike BoS where one of the rewards was substantially higher than the other. Due to the higher stakes, we thought pairs might coordinate more on these trials. The other trials were sampled  in a 16:10:10 ratio from normal BoS, easy PD and hard PD for an overall roughly half BoS and half PD mixture. 

When randomly sampling numbers to populate PD trials, generally, the welfare maximizing option (highest summed reward) comes from both cooperating. Sometimes, however the payout for defecting is greater than twice the both-cooperate value and so the welfare maximizing option is to agree to defect-cooperate. Thus, in this situation, one might be able to cooperate for an overall better outcome than could otherwise be achieved, so we aimed to see whether people would recognize this type and whether language use would help. 

*Expt 4* (https://osf.io/fymjc): In experiment 4, we tried to get a set-up that was closer to the predictions from game theory. We switched from providing a bonus proportional to the overall points earned to an incentive compatible bonus that sampled 4 trials at random and paid out those points. We also removed the points counter, given that participants previously reported using the visible money earned so far as a coordination locus. Games were a mix of roughly half easy PD and half normal BoS. 

*Expt 5* (https://osf.io/ksjmv): After a less successful experiment 4, we went back to the design of experiment 3. The condition distribution and incentive structure of experiment 5 was identical to experiment 3. Experiment 5 retained the modified pre-chat from experiment 4 that emphasized the absense of chatbots. 

## Data processing
All data processing was done in R, the code is available. TODO

# Results

the goal was to look at how people might use langauge to coordinate and thus achieve better outcomes than they could without language. We were also interested in what sort of coordination language might be used, and whether procedural or meta-conventions might occur. 

In terms of outcomes, we can look at points earned (which includes the random noise from what the points spreads were). We can also look at what outcome quadrant participants are selecting. 

One issue that arose was that we had some difficulty convincing participants their partners were indeed real humans, and substantial difficulty creating a situation where people in the chat condition would choose to use the chat. 

We also do analysis breaking out our chat condition into whether or not people chose to use the chat. However, this breaks the randomization and introduces as confounds any exogenous factor (other than access to chat) that determines whether people chat (i.e. contentiousness, motivation, etc). 

## Manipulation results

The interpretability of results depends on two factors: a) whether participants generally think they are playing with another human and b) whether chat use actually differs substantially by condition. 


```{r bot}
exit_1 <- read_csv(here(study_1_loc, "exit.csv")) |>
  group_by(game_cond, chat_cond, human) %>%
  tally() %>%
  pivot_wider(names_from = human, values_from = n) %>%
  mutate(pct = yes / (no + yes)) |>
  mutate(expt = str_c("1", "_", game_cond)) |>
  ungroup()

exit_2 <- read_csv(here(study_2_loc, "exit.csv")) |>
  group_by(chat_cond, human) %>%
  tally() %>%
  pivot_wider(names_from = human, values_from = n) %>%
  mutate(pct = yes / (no + yes)) |>
  mutate(expt = "2")

exit_3 <- read_csv(here(study_3_loc, "exit.csv")) |>
  group_by(chat_cond, human) %>%
  tally() %>%
  pivot_wider(names_from = human, values_from = n) %>%
  mutate(pct = yes / (no + yes)) |>
  mutate(expt = "3")

exit_4 <- read_csv(here(study_4_loc, "exit.csv")) |>
  group_by(chat_cond, human) %>%
  tally() %>%
  pivot_wider(names_from = human, values_from = n) %>%
  mutate(pct = yes / (no + yes)) |>
  mutate(expt = "4")

exit_5 <- read_csv(here(study_5_loc, "exit.csv")) |>
  group_by(chat_cond, human) %>%
  tally() %>%
  pivot_wider(names_from = human, values_from = n) %>%
  mutate(pct = yes / (no + yes)) |>
  mutate(expt = "5")

exit <- exit_1 |>
  bind_rows(exit_2) |>
  bind_rows(exit_3) |>
  bind_rows(exit_4) |>
  bind_rows(exit_5) |>
  select(expt, chat_cond, pct) |>
  mutate(chat_cond = ifelse(chat_cond == "chat", "chat", "nochat"))

exit |>
  mutate(pct = round(pct * 100, 1)) |>
  pivot_wider(names_from = chat_cond, values_from = pct) |>
  kable(caption = "Percent of participants in each condition who thought their partner was human as reported in an exit survey. \\label{human}")
```

For the most part, we succeeded in convincing players their partner was indeed human (Table \ref{human}). Rates of believing partner was human were slightly higher in the chat conditions than no-chat conditions. 

Our other manipulation check was how well participants took up the manipulation of being able to use a chat to communicate with their partner. 

As shown in Figure  \ref{chat-pct}, groups vary substantially in how many trials they use the chat on, but many groups rarely use the chat. The horizontal lines correspond to 10% and 50% of the time, so games lower than the 10% line are using chat on fewer than 4 (out of 40) trials. There's a lot of not chatting in the access-to-chat condition.  


```{r chat-pct, fig.width=10, fig.height=3, fig.cap="In chat conditions, how many trials each game choose to use the chat at all. Within each experiment, games are arranged in frequency of chat use. Horizontal lines denote 10% and 50% use of chat. \\label{chat-pct}"}

game_chat <- all_chat %>%
  filter(!is.na(targets)) %>%
  select(-type) %>%
  full_join(all_rounds) %>%
  mutate(words = str_count(text, "\\W+") %|% int(0)) |>
  group_by(gameId, gametype, cond, chat_cond, repNum, expt) %>%
  summarize(
    words = sum(words),
    mean_payout = mean(payoff),
    is_chat = ifelse(words > 0, 1, 0)
  )

game_chat |>
  filter(chat_cond == "chat") |>
  mutate(is.chat = ifelse(words > 0, 1, 0)) %>%
  group_by(gameId, expt) %>%
  summarize(pct_chat = mean(is.chat)) |>
  arrange(expt, pct_chat) |>
  group_by(expt) |>
  mutate(x = 1 / n() * row_number()) |>
  ggplot(aes(x = x, y = pct_chat)) +
  geom_point() +
  facet_grid(.~expt) + 
  geom_hline(yintercept = .1) +
  geom_hline(yintercept = .5) +
  labs(x="Fraction games", y="Fraction trials with chat messages")+
    scale_x_continuous(breaks=c(0, .25, .5, .75, 1), labels=c("0", ".25", ".5", ".75", "1"))+
      scale_y_continuous(breaks=c(0, .25, .5, .75, 1), labels=c("0", ".25", ".5", ".75", "1"))
```

## Main results


```{r}
msum_loc="manuscript/model_files/summary"

payout_mega <- read_rds(here(msum_loc, "payout_mega.rds"))
                        
payout_combo <- read_rds(here(msum_loc,"payout_mega_combo.rds"))
payout_3 <- read_rds(here(msum_loc, "payout_combo_3.rds"))
payout_4 <- read_rds(here(msum_loc, "payout_combo_4.rds"))
payout_5 <- read_rds(here(msum_loc, "payout_combo_5.rds"))

# 
bos_aligned <- read_rds(here(msum_loc, "BoS_aligned_mega.rds"))
bos_3 <- read_rds(here(msum_loc, "BoS_aligned_3.rds"))
bos_4 <- read_rds(here(msum_loc, "BoS_aligned_4.rds"))
bos_5 <- read_rds(here(msum_loc, "BoS_aligned_5.rds"))

PD_cooperate <- read_rds(here(msum_loc, "PD_cooperate_mega.rds"))
PD_unneven <- read_rds(here(msum_loc, "PD_unneven_mega.rds"))

```

The prediction is that having access to the communication modality will be helpful for aligning coordination in BoS where both players want to choose the same thing. 

Coordination should be less helpful in PD. According to theory, for single-shot, rational actors should choose the nash equilibrium. Participants are nicer than that and instead coordinate on the unstable mutually beneficial equilibrium. 

After observing that occasionally there were PD trials were the welfare-maximizing option was for one person to get a large payout and the other to get nothing (called "hard" or "sacrifice" PD trials in expt 3 onwards), we explicitly sampled both this "hard" structure where the best overall outcome is to coordinate on one person getting the big reward and balance out later by switching off. 

In contrast, we refer to the trials in which only one option is welfare maximizing as "easy PD" where we do not expect language to help. 

The first way we assess whether access to chat makes a difference on game performance is to look at the mean number of points received per trial. Because BoS and PD have different point structures, we compare within game type. 


```{r points, fig.cap="Rewards achieved per trial depending on experiment, game condition, and chat condition. \\label{points}"}

pal = c("PD_easy"="#1B9E77FF","PD_normal"= "#D95F02FF", "PD_hard"="#7570B3FF", "BoS_normal"= "#E7298AFF", "BoS_spike"="#66A61EFF")
bonuses <- all_rounds %>%
  group_by(playerId, gameId, chat_cond, cond, gametype, expt) %>%
  summarize(payoff = mean(payoff)) |> 
  mutate( combo_type=str_c(gametype, "_", cond) |> factor(levels=c("PD_easy", "PD_normal", "PD_hard", "BoS_normal", "BoS_spike")))



ggplot(bonuses, aes(x = chat_cond, y = payoff, color = combo_type, group = cond)) +
  geom_point(position = position_jitterdodge(jitter.width = .1, dodge.width = .7), alpha = .3) +
  facet_grid(gametype~expt) +
  scale_color_manual(values=pal) +
  labs(y = "mean_reward", x = "condition") +
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .7), size = .3, color = "black") +
    stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .7), size = .7, color = "black", geom="line") +
guides(color = guide_legend(override.aes = list(alpha = 1, size=3)))+
  theme(legend.position = "bottom") +
  coord_cartesian(ylim = c(0, 20)) +
  labs(y = "Mean reward / trial", ) +
  theme(
    legend.title=element_blank(),
    axis.title.x=element_blank()
  )
```
Points earned per trial in different games are shown in Figure \ref{points}, which suggests slight differences in reward for BoS games depending on chat versus nochat condition, and no differences for PD. 
In a model of payouts by coarse conditions (BoS v PD), there is an interaction between condition and chat condition where chat condition leads to higher payout for BoS (`r stats_text(payout_mega, 4)`). Using finer grained measures of condition, and treating "easy PD" as baseline, there are interactions between chat and both normal BoS (`r stats_text(payout_combo, 7)`) and spike BoS (`r stats_text(payout_combo, 8)`). The same directionality occurs in individual experiments, but with wide credible intervals. In Experiment 3, the chat interaction with normal BoS is `r stats_text(payout_3, 6)` and with spike BoS is `r stats_text(payout_3, 7)`. In Experiment 4, the interaction between chat and normal BoS is `r stats_text(payout_4, 4)`. In Experiment 5, the chat interaction with normal BoS is `r stats_text(payout_5, 6)` and with spike BoS is `r stats_text(payout_5, 7)`. Full model results are in the Appendix. 


In BoS, there is a generally a slightly higher score in the chat condition than the nochat condition, whereas there is not a difference between condtions in PD. 

Looking at points introduces some noise as the points were varying even within a type of game. To understand more what is being selected, we can look at what quadrant games are ending up in.


### Quadrant analysis per trial

```{r}
outcome <- all_rounds %>%
  select(gameId, repNum, response, chat_cond, gametype, cond, role) |>
  pivot_wider(names_from = role, values_from = response) %>%
  mutate(outcome = str_c(p1, p2)) %>%
  left_join(game_chat) |> 
   mutate( combo_type=str_c(gametype, "_", cond) |> factor(levels=c("PD_easy", "PD_normal", "PD_hard", "BoS_normal", "BoS_spike")))

```

For BoS, the desirable outcome is to both choose the same box. As can be seen in Figure \ref{bosquad}, this good outcome is achieved at above change levels when people can chat and usually at chance levels when people cannot. Across experiments, the chat condition has a higher rate of good (aligned) outcomes (`r stats_text(bos_aligned, 3)`). The estimates are less certain for individual experiments. In experiment 3 the effect was `r stats_text(bos_3, 3)`; in experiment 4, `r stats_text(bos_4,2)`; and in experiment 5, `r stats_text(bos_5,3)`. 

```{r bosquad, fig.cap="For BoS trials, how frequently pairs made coordinated selections that recieved rewards. \\label{bosquad} ", fig.height=3, fig.width=8}
outcome %>%
  filter(gametype == "BoS") %>%
  mutate(outcome_parity = ifelse(outcome %in% c("AA", "BB"), 1, 0)) %>%
  ggplot(aes(x = str_c(chat_cond), y = outcome_parity, color=combo_type, group=combo_type)) +
  facet_grid(~ expt) +
  scale_color_manual(values=pal)+
  stat_summary(fun.data = "mean_cl_boot", position=position_dodge(width=.3)) +
  geom_hline(aes(yintercept = .5)) +
  labs(y = "Good outcome?", x="Chat condition", color="")+
  theme(legend.position="bottom")
```
We again note that the off-diagonal rewards were misdisplayed for one of the players in experiments 1 and 2 for PD. On most trials "normal_PD" will pattern with easy PD. 

In easyPD: P1 prefers BA > AA > BB > AB and P2 prefers AB > AA > BB > BA. AA is welfare maximizing.

In hardPD: P1 prefers BA > AA > BB > AB and P2 prefers AB > AA > BB > BA. BA and AB are welfare maximizing.


```{r , fig.cap="For PD trials, how frequently pairs made selections that results in each type of outcome. AA is the cooperate outcome, AB/BA is mixed -- one cooperate, one defect, BB is both defect. \\label{pdquad} ", fig.height=5, fig.width=8}
outcome %>%
  filter(gametype == "PD") %>%
  mutate(AA = ifelse(outcome %in% c("AA"), 1, 0)) %>%
  mutate(AB_BA= ifelse(outcome %in% c("AB", "BA"), 1, 0)) %>%
  mutate(BB = ifelse(outcome %in% c("BB"), 1, 0)) %>%
  pivot_longer(c("AA", "AB_BA", "BB"), names_to="outcome_type", values_to="selected") |> 
  ggplot(aes(x = chat_cond, y = selected, color=combo_type)) +
  facet_grid(outcome_type ~ expt) +
    scale_color_manual(values=pal)+

  stat_summary(fun.data = "mean_cl_boot", position=position_dodge(width=.3)) +
  geom_hline(aes(yintercept = .5)) +
  labs(y="fraction selected", x="Chat condition", color="")+
  theme(legend.position="bottom")
```
From Figure \ref{pdquad}, we see that the preferred outcome is AA which is welfare-maximizing in easy PD. This is not what game theory predicts for rational actors, instead, participants are being nice and cooperative with each other. 

Overall, for PD, the preference was to align on the fair-but-high square, regardless of whether chat was available. In the hard PD, AA selections were less common (`r stats_text(PD_cooperate, 2)`) and AA selections were slightly lowered still by a hard PD x chat interaction (`r stats_text(PD_cooperate, 5)`). The interaction effect had a credible interval overlapping 0 when experiments 3 or 5 were analyzed individually.  In parallel, there was a hard PD x chat interaction increasing the rate of AB/BA selections (`r stats_text(PD_unneven, 5)`), consistent with the idea that this is the best outcome for hard PD, but requires more complex coordination to achieve. 

Overall, the results based on condition assignment are consistent with the prediction that language would be more beneficial for BoS than for PD. However, conditional differences are small and often noisy (presumably due to low update of using language), and so the experiments do not provide compelling evidence. 

## Uptake results

To confirm that language use is, indeed useful, we also provide visualizations looking at both the option and choice to use language on a trial by trial basis. Note that a pairs' choice to use language is not assigned and thus this exploratory analysis could be confounded. 

```{r}
outcome_chatted <- outcome |> 
  mutate(chatted = case_when(
    chat_cond =="nochat" ~ "nochat",
    is_chat == 1 ~ "chatted",
    is_chat == 0 ~ "quiet"
  ) |> factor(levels=c("chatted", "quiet", "nochat")))
```

In BoS: P1 prefers AA to BB, P2 prefers BB to AA. AB and BA are 0 for both. 

```{r, fig.cap="For BoS trials, how frequently pairs made coordinated selections that recieved rewards as a function of whether chat was available or used that trial. \\label{bosquad-uptake} ", fig.height=3, fig.width=8}
outcome_chatted %>%
  filter(gametype == "BoS") %>%
  mutate(outcome_parity = ifelse(outcome %in% c("AA", "BB"), 1, 0)) %>%
  ggplot(aes(x = chatted, y = outcome_parity, color=combo_type, group=combo_type)) +
  facet_grid(~ expt) +
  scale_color_manual(values=pal)+
  stat_summary(fun.data = "mean_cl_boot", position=position_dodge(width=.3)) +
  geom_hline(aes(yintercept = .5)) +
  labs(y = "Good outcome?", x="Chat usage on trial", color="")+
  theme(legend.position="bottom")
```
For BoS results, shown in Figure \ref{bosquad-uptake}, the outcomes are best on trials that chatted. Depending on experiment, trials that could talk are either intermediate, or pattern with the nochat condition. This pattern suggests that some of the benefits to chatting spill over onto other trials, perhaps via setting up conventions for determining what strategy to use to break the symmetry. However, most of the overall slight benefits from the chat condition are being driven by the small number of games and trials that used the chat. 


```{r, fig.cap="For PD trials, how frequently pairs made selections that results in each type of outcome as a function of chat availability and usage on each trial. AA is the cooperate outcome, AB/BA is mixed -- one cooperate, one defect, BB is both defect. \\label{pdquad} ", fig.height=5, fig.width=8}
outcome_chatted %>%
  filter(gametype == "PD") %>%
  mutate(AA = ifelse(outcome %in% c("AA"), 1, 0)) %>%
  mutate(AB_BA= ifelse(outcome %in% c("AB", "BA"), 1, 0)) %>%
  mutate(BB = ifelse(outcome %in% c("BB"), 1, 0)) %>%
  pivot_longer(c("AA", "AB_BA", "BB"), names_to="outcome_type", values_to="selected") |> 
  ggplot(aes(x = chatted, y = selected, color=combo_type)) +
  facet_grid(outcome_type ~ expt) +
    scale_color_manual(values=pal)+

  stat_summary(fun.data = "mean_cl_boot", position=position_dodge(width=.3)) +
  geom_hline(aes(yintercept = .5)) +
  labs(color="", y="Selected", x="Chat usage on trial" )+
  theme(legend.position="bottom")
```

We similarly break down the PD results in terms of language use per trial in Figure \ref{pdquad}. 
Noteably, the selection of AB/BA options in hard PD is primarly being driven by trials where people did communicate with each other. 

## Use of language 

From the uptake analysis, it appears that using chat has some benefits, especially on BoS trials. Does the amount of language used matter, or only its existance? In Figure \ref{wordpayout}, we compare rewards on a trial as a function of the number of words used, for trials where any language was used. Overall, there does not seem to be a benefit to using more words on a trial. 

```{r, fig.cap="On trials that used the chat, the relationship between number of words and the reward, for each experiment and condition. \\label{wordpayout} ", fig.height=4, fig.width=8}
game_chat |> filter(words > 0) |> 
   mutate( combo_type=str_c(gametype, "_", cond) |> factor(levels=c("PD_easy", "PD_normal", "PD_hard", "BoS_normal", "BoS_spike"))) |> 
  ggplot(aes(x = words, y = mean_payout, color=combo_type)) +
  scale_x_log10(breaks=c(1,5,25))+
  scale_color_manual(values=pal)+
  geom_point(alpha=.1) +
  facet_grid(gametype ~ expt) +
  geom_smooth(method = "lm", show.legend=F)+
  guides(color = guide_legend(override.aes = list(alpha = 1, size=3)))+
  theme(legend.position="bottom")+
  labs(color="", x="Words in a trial", y="Reward")

```

The utility of language, but without a clear dose-response relationship, suggests that the language may primarily be used for coordination rather than negotiation. 

A qualitative perusal of the data suggests various strategies. On a trial by trial reference basis, cells can be identified by color or color combination, sometimes even reducing to single letter (such as r for red). The numeric values can also be used to identify. 

Between the chat logs and the post game strategy notes, a number of strategies were identified. For example, some participants coordinated using the running score totals choosing the option that favored the person with a lower current score. Other identified strategies included fairness, being generous to the other person, or generally being fair but occassionally trying to take advantage and get a higher payout. 

# Discussion 
Some caveats: Despite our desire to use game-theory aligned paradigms for the analytic theory and predictions, the experiments had several factors that cause potential theoretical misalignment. 

1. For practical reasons, we ran repeated trials with the same partners. This iterated approach is also studied, but potentially changes what exactly the predictions are. 

2. The incentives of participants are not the same as the incentives of the "agents". People have values above money such as their reputation and desire to be nice to other people. Additionally, the monetary value participants get from the task is not what is shown in the boxes. They were paid a base rate for participation + a bonus aligned to task performance. Strategies of random clicking could be cost efficient if it means the task takes sufficiently shorter that base rate / short time is a better wage than (base rate + higher bonus)/ longer time. 

3. The repeated nature of the game and extra information such as running score allowed for coordinating in ways not available in the base single-shot games. 

One of the hopes was to see if using language on some perhaps early trials would set up conventions or patterns that could then be successfully executed on later with no or little additional language. 

# Appendix: Model Results

Here we present the statistical results we ran. Note that these are not all the statistics we ever ran and may not be the pre-registered ones. These are what I thought best summarized the data descriptively and addressed the hypotheses at the time this summary was written. 

```{r}
form <- function(model) {
  dep <- as.character(model$formula[2])
  ind <- as.character(model$formula[3])

  str_c(dep, " ~ ", ind) |>
    str_replace_all(" ", "") |>
    str_replace_all("~", "~$\\\\sim$ ") |>
    str_replace_all("\\*", "~$\\\\times$ ") |>
    str_replace_all("\\+", "~+ ") |>
    str_replace_all("_", "")
}

do_table <- function(mod, cap, decimal = 2) {
  model <- read_rds(here(msum_loc, mod)) |>
    mutate(
      Estimate = round(Estimate, digits = decimal),
      Term = str_replace_all(Term, "_", ""),
      Lower = round(lower, digits = decimal),
      Upper = round(upper, digits = decimal),
      `Credible Interval` = str_c("[", Lower, ", ", Upper, "]")
    ) |>
    select(Term, Estimate, `Credible Interval`)

  spec <- read_rds(here(mform_loc, mod))

  kable(model |> select(Term, Est. = Estimate, `95\\% CrI` = `Credible Interval`),
    escape = F, format = "latex", booktabs = T, linesep = "",
    caption = str_c(cap, ": ", form(spec), sep = ""),
    align = "lll", position="H"
  )
}

msum_loc="manuscript/model_files/summary"
mform_loc="manuscript/model_files/formulae"
```

## Payout models

These models all predict bonus score as an outcome in terms of either the coarse grained conditions (PD v BoS) or the finer grained conditions, all with interactions with assigned chat condition. 

Priors were normal(5,2) for intercept and normal(0,2) for beta and sd. Model were run both over all the experiments, and individually on each of experiments 3-5. Due to errors, we do not run separate models on 1 and 2. 

```{r}
do_table("payout_mega.rds", cap="Mega-analytic model predicting bonus based on coarse game type and chat condition.")
do_table("payout_mega_combo.rds", cap="Mega-analytic model predicting bonus based on fine-grained game type and chat condition.")
do_table("payout_combo_3.rds", cap="Model predicting bonus for experiment 3. ")
do_table("payout_combo_4.rds", cap="Model predicting bonus for experiment 4. ")
do_table("payout_combo_5.rds", cap="Model predicting bonus for experiment 5. ")

```

\FloatBarrier

## BoS models

Abstracting over the randomly selected payout values, we also examined each class of game by where the selections fell in the 2x2 grid. For BoS, due to symmetry, outcomes are either aligned (positive outcome) or misaligned (0 value outcome). We can look at the effect of chat on getting aligned outcomes. 

These were logistic models with a prior of normal(0,1) for beta and sd. 

```{r}
do_table("BoS_aligned_mega.rds", cap="Mega-analytic model predicting occurrance of aligned outcome in BoS. ")
do_table("BoS_aligned_3.rds", cap="Model predicting aligned BoS outcome for experiment 3. ")
do_table("BoS_aligned_4.rds", cap="Model predicting aligned BoS outcome for experiment 4. ")
do_table("BoS_aligned_5.rds", cap="Model predicting aligned BoS outcome for experiment 5. ")

```

## PD models 

For PD, there are 3 different outcomes. The AA cooperative outcome, the AB/BA outcome, and the Nash equilibrium BB outcome. We ran separate logistic models for the occurrence of each outcome, although note that model results are inherently interdependent because each trial has exactly 1 of these outcomes. 

These were logistic models with a prior of normal(0,1) for beta and sd. 

```{r}
do_table("PD_cooperate_mega.rds", cap="Mega-analytic model predicting AA outcomes in PD trials")
do_table("PD_cooperate_3.rds", cap="Model predicting AA outcomes in PD trials for experiment 3.")
do_table("PD_cooperate_4.rds", cap="Model predicting AA outcomes in PD trials for experiment 4.")
do_table("PD_cooperate_5.rds", cap="Model predicting AA outcomes in PD trials for experiment 5.")


do_table("PD_unneven_mega.rds", cap="Mega-analytic model predicting AB/BA outcomes in PD trials. ")
do_table("PD_unneven_3.rds", cap="Model predicting AB/BA outcomes in PD trials for experiment 3.")
do_table("PD_unneven_4.rds", cap="Model predicting AB/BA outcomes in PD trials for experiment 4.")
do_table("PD_unneven_5.rds", cap="Model predicting AB/BA outcomes in PD trials for experiment 5.")


do_table("PD_nash_mega.rds", cap="Mega-analytic model predicting BB (Nash equilibrium) outcomes in PD trials.")
do_table("PD_nash_3.rds", cap="Model predicting BB outcomes in PD trials for experiment 3.")
do_table("PD_nash_4.rds", cap="Model predicting BB outcomes in PD trials for experiment 4.")
do_table("PD_nash_5.rds", cap="Model predicting BB outcomes in PD trials for experiment 5.")



```

